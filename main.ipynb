{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HnqYfEwix7b"
      },
      "source": [
        "# Import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dMKo6nyrvWoD"
      },
      "outputs": [],
      "source": [
        "x_train = np.load('public_dataset.npy')\n",
        "y_train = np.load('public_solution.npy')\n",
        "x_compet = np.load('private_dataset.npy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBupM8j_86GJ"
      },
      "source": [
        "# Train - test split\n",
        "\n",
        "To limit the lack of training samples for the first classes, the test set will not have any images for the first 15 classes. The test set is composed of 10 images from the 15th to the 1,000th class. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OWQrfJZm85t_"
      },
      "outputs": [],
      "source": [
        "data = [x_train[y_train == i] for i in range(100)] \n",
        "k = 10\n",
        "start = 15\n",
        "test_data = [data[i][:k] for i in range(start,len(data))]\n",
        "train_data = data[:start] + [data[i][k:] for i in range(start,len(data))]\n",
        "y_test = np.array([i for i in range(len(test_data)) for j in range(len(test_data[i]))]) +start\n",
        "x_test = np.concatenate(test_data)\n",
        "\n",
        "y_train = np.array([i for i in range(len(train_data)) for j in range(len(train_data[i]))]) \n",
        "x_train = np.concatenate(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQOHhrihGLRw"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUxW-tN8JCMy",
        "outputId": "bbea0e1e-9703-43f0-f2df-eca568bd0545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train (49650, 28, 28)\n",
            "y_train (49650,)\n",
            "x_compet (100000, 28, 28)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"x_train\",np.shape(x_train))\n",
        "print(\"y_train\",np.shape(y_train))\n",
        "print(\"x_compet\",np.shape(x_compet))\n",
        "plt.hist(y_train,bins=range(102))\n",
        "plt.plot()\n",
        "plt.hist(y_test,bins=range(102))\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv7IX0v-JXDY",
        "outputId": "5e0cb9db-805d-4fd2-f04b-70558842ff61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 10, 1: 20, 2: 30, 3: 40, 4: 50, 5: 60, 6: 70, 7: 80, 8: 90, 9: 100, 10: 110, 11: 120, 12: 130, 13: 140, 14: 150, 15: 150, 16: 160, 17: 170, 18: 180, 19: 190, 20: 200, 21: 210, 22: 220, 23: 230, 24: 240, 25: 250, 26: 260, 27: 270, 28: 280, 29: 290, 30: 300, 31: 310, 32: 320, 33: 330, 34: 340, 35: 350, 36: 360, 37: 370, 38: 380, 39: 390, 40: 400, 41: 410, 42: 420, 43: 430, 44: 440, 45: 450, 46: 460, 47: 470, 48: 480, 49: 490, 50: 500, 51: 510, 52: 520, 53: 530, 54: 540, 55: 550, 56: 560, 57: 570, 58: 580, 59: 590, 60: 600, 61: 610, 62: 620, 63: 630, 64: 640, 65: 650, 66: 660, 67: 670, 68: 680, 69: 690, 70: 700, 71: 710, 72: 720, 73: 730, 74: 740, 75: 750, 76: 760, 77: 770, 78: 780, 79: 790, 80: 800, 81: 810, 82: 820, 83: 830, 84: 840, 85: 850, 86: 860, 87: 870, 88: 880, 89: 890, 90: 900, 91: 910, 92: 920, 93: 930, 94: 940, 95: 950, 96: 960, 97: 970, 98: 980, 99: 990}\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "dic = dict(zip(unique, counts))\n",
        "print(dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtOrtY7VMJz_",
        "outputId": "b569f1a3-db31-4711-f7dc-2710c48a775d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 504x504 with 16 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig = plt.figure(figsize=(7,7))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.gray)\n",
        "    plt.title(label=f\"{y_train[i]}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wva6iCEMrQx"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "As the test set is balanced, the model should not be biased on the predicted classes because of the training distribution. To do that, the dataset is randomly augmented to have the exact same number of samples in each class. \n",
        "\n",
        "The dataset is augmented with random rotation, cropping, horizontal flipping and zooming. Each class is augmented until reaching 1,500 images per class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3sbtBMhOnPnw"
      },
      "outputs": [],
      "source": [
        "x_train = np.reshape(x_train,(len(x_train),28,28,1))\n",
        "x_test = np.reshape(x_test,(len(x_test),28,28,1))\n",
        "x_compet = np.reshape(x_compet,(len(x_compet),28,28,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Dv-j3ytLMyrY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "#train_datagen.random_transform(image) pour appliquer une transfo\n",
        "#image doit être de la forme (28,28,1)\n",
        "\n",
        "# perform data augmentation\n",
        "# data aug pour tripler le nombre d'images de chaque classe \n",
        "data = [x_train[y_train == i] for i in range(100)]\n",
        "for ind in range(len(data)) :\n",
        "    #print(ind)\n",
        "    clas = data[ind]\n",
        "    nb_base = np.shape(clas)[0]\n",
        "    for _ in range(1500-np.shape(clas)[0]):\n",
        "        nb = np.random.randint(0,nb_base)\n",
        "        image = clas[nb]\n",
        "        new_im = train_datagen.random_transform(image)\n",
        "        data[ind] = np.append(data[ind],[new_im],axis=0)\n",
        "y_train = np.array([i for i in range(len(data)) for j in range(len(data[i]))])\n",
        "x_train = np.concatenate(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lu5Q3f7ZX59e"
      },
      "source": [
        "# Preprocessing \n",
        "\n",
        "One-hot encoding for labels et standardization for images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qr8rlBX2vo1C"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train)\n",
        "x_train = x_train / 255 - 0.5 \n",
        "y_test = to_categorical(y_test)\n",
        "x_test = x_test / 255 - 0.5\n",
        "x_compet = x_compet/ 255 - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuyPNoQ7eSk4",
        "outputId": "8216ea0c-9c10-461d-d4bf-b612274eb6d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150000, 28, 28, 1)\n",
            "(150000, 100)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(x_train))\n",
        "print(np.shape(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lsh9Zhqfy0cy"
      },
      "outputs": [],
      "source": [
        "#shuffle arrays\n",
        "def shuffle_arrays(x_train,y_train):\n",
        "    p = np.random.permutation(len(x_train))\n",
        "    return x_train[p],y_train[p]\n",
        "\n",
        "x_train,y_train = shuffle_arrays(x_train,y_train)\n",
        "x_test,y_test = shuffle_arrays(x_test,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLU87D3ztwvE"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHm7slNUvwzL",
        "outputId": "1660b0c0-2fbe-4191-daee-cf2aa739b527"
      },
      "outputs": [],
      "source": [
        "def baseCNN():\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.Input(shape=(28, 28,1)))  \n",
        "    model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
        "    model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(100,activation='softmax'))\n",
        "    return model \n",
        "\n",
        "model = baseCNN()\n",
        "#model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxZN6R67CuMr",
        "outputId": "483e2d74-ebf1-4d14-d410-524814ea725a"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class Residual(layers.Layer):\n",
        "    def __init__(self, n1, k1, s1, n2, k2, s2):\n",
        "        super(Residual, self).__init__()\n",
        "        self.conv1 = layers.Conv2D(n1,k1,strides =(s1,s1),padding='same')\n",
        "        self.relu1 = layers.LeakyReLU()\n",
        "        self.conv2 = layers.Conv2D(n2,k2,strides=(s2,s2),padding='same')\n",
        "        self.add1 = layers.Add()\n",
        "        self.relu2 = layers.LeakyReLU()\n",
        "    def call(self,input):\n",
        "        y = self.conv1(input)\n",
        "        y = self.relu1(y)\n",
        "        y = self.conv2(y)\n",
        "        y = self.add1([input, y])\n",
        "        y = self.relu2(y)\n",
        "        return y \n",
        "\n",
        "def resnet():\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    y = layers.Conv2D(32,3,padding='valid')(input_layer)\n",
        "    y = Residual(32,3,1,32,3,1)(y)\n",
        "    y = layers.Conv2D(64,3,strides=(2,2),padding='valid')(y)\n",
        "    y = Residual(64,3,1,64,3,1)(y)\n",
        "    y = layers.Conv2D(128,3,strides=(2,2),padding='valid')(y)\n",
        "    y = Residual(128,3,1,128,3,1)(y)\n",
        "    y = layers.Conv2D(128,2,2)(y)\n",
        "    y = layers.Conv2D(100,1,2)(y)\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    return model\n",
        "\n",
        "model = resnet()\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MobileNet v2 \n",
        "\n",
        "Many variations have been tested on this one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxG3gHl5AMAn",
        "outputId": "8412c1cc-4f19-4bc8-ef2e-fdbb095c87ae"
      },
      "outputs": [],
      "source": [
        "#mobile net v2 n°1 \n",
        "\n",
        "\n",
        "#from typeguard import typechecked\n",
        "\n",
        "class StochasticDepth(tf.keras.layers.Layer):\n",
        "    \"\"\"Stochastic Depth layer.\n",
        "    Implements Stochastic Depth as described in\n",
        "    [Deep Networks with Stochastic Depth](https://arxiv.org/abs/1603.09382), to randomly drop residual branches\n",
        "    in residual architectures.\n",
        "    Usage:\n",
        "    Residual architectures with fixed depth, use residual branches that are merged back into the main network\n",
        "    by adding the residual branch back to the input:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tf.keras.layers.Add()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    StochasticDepth acts as a drop-in replacement for the addition:\n",
        "    >>> input = np.ones((1, 3, 3, 1), dtype = np.float32)\n",
        "    >>> residual = tf.keras.layers.Conv2D(1, 1)(input)\n",
        "    >>> output = tfa.layers.StochasticDepth()([input, residual])\n",
        "    >>> output.shape\n",
        "    TensorShape([1, 3, 3, 1])\n",
        "    At train time, StochasticDepth returns:\n",
        "    $$\n",
        "    x[0] + b_l * x[1],\n",
        "    $$\n",
        "    where $b_l$ is a random Bernoulli variable with probability $P(b_l = 1) = p_l$\n",
        "    At test time, StochasticDepth rescales the activations of the residual branch based on the survival probability ($p_l$):\n",
        "    $$\n",
        "    x[0] + p_l * x[1]\n",
        "    $$\n",
        "    Args:\n",
        "        survival_probability: float, the probability of the residual branch being kept.\n",
        "    Call Args:\n",
        "        inputs:  List of `[shortcut, residual]` where `shortcut`, and `residual` are tensors of equal shape.\n",
        "    Output shape:\n",
        "        Equal to the shape of inputs `shortcut`, and `residual`\n",
        "    \"\"\"\n",
        "\n",
        "    #@typechecked\n",
        "    def __init__(self, survival_probability: float = 0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.survival_probability = survival_probability\n",
        "\n",
        "    def call(self, x, training=None):\n",
        "        if not isinstance(x, list) or len(x) != 2:\n",
        "            raise ValueError(\"input must be a list of length 2.\")\n",
        "\n",
        "        shortcut, residual = x\n",
        "\n",
        "        # Random bernoulli variable indicating whether the branch should be kept or not or not\n",
        "        b_l = tf.keras.backend.random_bernoulli(\n",
        "            [], p=self.survival_probability, dtype=self._compute_dtype_object\n",
        "        )\n",
        "\n",
        "        def _call_train():\n",
        "            return shortcut + b_l * residual\n",
        "\n",
        "        def _call_test():\n",
        "            return shortcut + self.survival_probability * residual\n",
        "\n",
        "        return tf.keras.backend.in_train_phase(\n",
        "            _call_train, _call_test, training=training\n",
        "        )\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "\n",
        "        config = {\"survival_probability\": self.survival_probability}\n",
        "\n",
        "        return {**base_config, **config}\n",
        "\n",
        "\n",
        "\n",
        "def mobile_big():\n",
        "    wd = 4e-5\n",
        "\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            self.drop1 = layers.Dropout(0.3)\n",
        "            self.drop2 = layers.Dropout(0.3)\n",
        "\n",
        "            if stride == 1 :\n",
        "                self.add1 = StochasticDepth(0.8)\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop1(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop2(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=2) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=3) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=4) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=3) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=2) #2\n",
        "    # (2,2,160)\n",
        "    #y = layers.Conv2D(300,1,1)(y)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1,kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(y)\n",
        "\n",
        "\n",
        "\n",
        "    #verifier shape ici puis continuer l'implé\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    #model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_311 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck_110 (Bottleneck)  (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_111 (Bottleneck)  (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_112 (Bottleneck)  (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_113 (Bottleneck)  (None, 4, 4, 64)          22144     \n",
            "_________________________________________________________________\n",
            "bottleneck_114 (Bottleneck)  (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_115 (Bottleneck)  (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_330 (Conv2D)          (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Softmax_6 (Tenso [(None, 100)]             0         \n",
            "=================================================================\n",
            "Total params: 291,404\n",
            "Trainable params: 285,708\n",
            "Non-trainable params: 5,696\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#mobile net v2 n°2\n",
        "# all repeats are set to 1\n",
        "def mobile2():\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same')\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same')\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same')\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same')\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same')(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=1) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    #y = layers.Conv2D(300,1,1)(y)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1)(y)\n",
        "\n",
        "\n",
        "\n",
        "    #verifier shape ici puis continuer l'implé\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    return model \n",
        "\n",
        "model = mobile2()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck (Bottleneck)      (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_1 (Bottleneck)    (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_2 (Bottleneck)    (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_3 (Bottleneck)    (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_4 (Bottleneck)    (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_5 (Bottleneck)    (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_6 (Bottleneck)    (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Softmax (TensorF [(None, 100)]             0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 303,020\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#mobile net v2 n°3\n",
        "\n",
        "def mobile3():\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same')\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same')\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same')\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same')\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same')(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=2) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1)(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    return model \n",
        "\n",
        "model = mobile3()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_15 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_269 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck_87 (Bottleneck)   (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_88 (Bottleneck)   (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_89 (Bottleneck)   (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_90 (Bottleneck)   (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_91 (Bottleneck)   (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_92 (Bottleneck)   (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_93 (Bottleneck)   (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_290 (Conv2D)          (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape_7 (Reshape)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Softmax_9 (Tenso [(None, 100)]             0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 303,020\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#mobile net v2 n°4\n",
        "# with weight decay \n",
        "\n",
        "def mobile4():\n",
        "    wd = 4e-5\n",
        "\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=2) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1,kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    return model \n",
        "\n",
        "model = mobile4()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mobile net v2 n°5\n",
        "# with weight decay\n",
        "# Dropout set to 0.2\n",
        "\n",
        "def mobile5():\n",
        "\n",
        "    wd = 4e-5\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            self.drop1 = layers.Dropout(0.2)\n",
        "            self.drop2 = layers.Dropout(0.2)\n",
        "\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop1(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop2(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=2) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1,kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    #model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mobile net v2 n°6\n",
        "# with weight decay\n",
        "# dropout set to 0.3, really slow to train\n",
        "\n",
        "def mobile6():\n",
        "    wd = 4e-5\n",
        "\n",
        "\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            self.drop1 = layers.Dropout(0.3)\n",
        "            self.drop2 = layers.Dropout(0.3)\n",
        "\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop1(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop2(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=2) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1,kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    #model.summary()\n",
        "    return model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#mobile net v2 n°7\n",
        "# with weight decay\n",
        "# with drop channel set to 0.2 \n",
        "\n",
        "def mobile7():\n",
        "\n",
        "    wd = 4e-5\n",
        "\n",
        "\n",
        "    class Bottleneck(layers.Layer):\n",
        "        def __init__(self,input_filters,output_filters,expansion,stride):\n",
        "            super(Bottleneck, self).__init__()\n",
        "            self.conv1 = layers.Conv2D(input_filters*expansion,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv2 = layers.DepthwiseConv2D(3,strides=(stride,stride),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.conv3 = layers.Conv2D(output_filters,1,strides =(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "            self.bn1 = layers.BatchNormalization()\n",
        "            self.bn2 = layers.BatchNormalization()\n",
        "            self.drop1 = layers.SpatialDropout2D(0.2)\n",
        "            self.drop2 = layers.SpatialDropout2D(0.2)\n",
        "\n",
        "            if stride == 1 :\n",
        "                self.add1 = layers.Add()\n",
        "            if input_filters != output_filters :\n",
        "                self.conv4 = layers.Conv2D(output_filters,1,strides=(1,1),padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))\n",
        "\n",
        "            self.input_filters = input_filters\n",
        "            self.output_filters = output_filters\n",
        "            self.stride = stride \n",
        "        \n",
        "        def get_config(self):\n",
        "        \n",
        "            config = super().get_config().copy()\n",
        "            config.update({\n",
        "                'input_filters': self.input_filters,\n",
        "                'output_filters': self.output_filters,\n",
        "                'stride': self.stride\n",
        "            })\n",
        "            return config\n",
        "\n",
        "        def call(self,input1):\n",
        "            input2 = input1\n",
        "            y = self.conv1(input1)\n",
        "            y = self.bn1(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop1(y)\n",
        "            y = self.conv2(y)\n",
        "            y = self.bn2(y)\n",
        "            y = tf.nn.relu6(y)\n",
        "            y = self.drop2(y)\n",
        "            y = self.conv3(y)\n",
        "            if self.stride == 2 :\n",
        "                return y \n",
        "            else :\n",
        "                if self.input_filters != self.output_filters :\n",
        "                    input2 = self.conv4(input2)\n",
        "\n",
        "            y = self.add1([input2,y])\n",
        "            return y \n",
        "\n",
        "\n",
        "    def BottleneckBlock(inputs,output_filters,expansion,stride,repeat):\n",
        "        y = inputs\n",
        "        input_filters = y.shape[3]\n",
        "        if repeat == 1:\n",
        "            y=Bottleneck(input_filters,output_filters,expansion,stride)(y)\n",
        "        else : \n",
        "            for i in range(repeat):\n",
        "                if i == 0 :\n",
        "                    y=Bottleneck(input_filters,input_filters,expansion,stride)(y)\n",
        "                else : \n",
        "                    y=Bottleneck(input_filters,output_filters,expansion,1)(y)\n",
        "                \"\"\"\n",
        "                elif i == repeat-1 :\n",
        "                    bottle.append(Bottleneck(input_filters,output_filters,expansion,1))\n",
        "                else :\n",
        "                    bottle.append(Bottleneck(input_filters,input_filters,expansion,1))\n",
        "                \"\"\"\n",
        "        return y \n",
        "        \n",
        "        \n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "\n",
        "    y = layers.Conv2D(32,3,padding='same',kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(input_layer)\n",
        "    # (28,28,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=16,expansion=1,stride=1,repeat=1)\n",
        "    # (28,28,16)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=24,expansion=6,stride=2,repeat=1) #2\n",
        "    # (14,14,24)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=32,expansion=6,stride=2,repeat=1) #3\n",
        "    # (7,7,32)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=64,expansion=6,stride=2,repeat=2) #4\n",
        "    # (4,4,64)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=96,expansion=6,stride=1,repeat=1) #3\n",
        "    # (4,4,96)\n",
        "    y = BottleneckBlock(inputs=y,output_filters=160,expansion=6,stride=2,repeat=1) #2\n",
        "    # (2,2,160)\n",
        "    y = layers.MaxPooling2D(pool_size=(2,2))(y)\n",
        "    y = layers.Conv2D(100,1,1,kernel_regularizer=regularizers.l2(wd), bias_regularizer=regularizers.l2(wd))(y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    y = layers.Reshape((100,))(y)\n",
        "    y = tf.keras.activations.softmax(y, axis=-1)\n",
        "    model = Model(input_layer,y)\n",
        "    #model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g64jALT3Hzp"
      },
      "source": [
        "Mon test set est constitué de 10 images de 85 classes \n",
        "Une accuracy acc sur ce test set conduit à une accuracy réelle sur un dataset equilibré de \n",
        "85/100 * acc + potentiellement 15% inconnus comme on n'a pas d'image de test pour cette partie \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wavgwheIPPs"
      },
      "source": [
        "Quelques exemples de valeurs :  \n",
        "\n",
        "val_acc = 67% -> 56% réel \n",
        "\n",
        "val_acc = 70% -> 59.5% réel \n",
        "\n",
        "val_acc = 76.5% -> 65% réel \n",
        "\n",
        "val_acc = 82.35% -> 70% réel \n",
        "\n",
        "Attention, ce sont des valeurs minimales donc on peut espérer un peu plus :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3LLEAhWJ2hT"
      },
      "source": [
        "Benchmarck  \n",
        "\n",
        "Val acc : 70%, 8 époques, resnet, data_aug de façon à avoir 1000 images dans chaque classe\n",
        "\n",
        "Val acc : 70% tout pareil, Data aug que sur le dataset reel \n",
        "\n",
        "Val acc : 70% tout pareil, mais data aug de façon à tripler le dataset d'entrainement mais à nuancer pcq probablement moins bon sur les 15 premières classes \n",
        "\n",
        "val acc : 69.5%, 9 époques, data aug poupr tripler le dataset, MobileNetV2\n",
        "\n",
        "Few shot learning -> de la merde.\n",
        "\n",
        "j'ai fait beaucoup de tests ensuite avec mobilenet \n",
        "globalement, j'ai des résultats autour de 70% pour toutes les archis en faisant varier les couches de mobilenetv2. Seul le modèle avec 687k paramètres donne des résultats meilleurs à 73%. Le reste a 300k param et tourne autour de 70%. Néanmoins, tous mes modèles overfittent très salement.\n",
        "J'essaie alors d'utiliser plein de techniques annexes pour augmenter mes perfs.\n",
        "Label smoothing me fait gagner un peu\n",
        "La régularisation retire l'overfit de départ et donne l'impression d'avoir un entrainement avec moins d'overfit \n",
        "Je passe ensuite au Dropout. Plusieurs choses à tester : droupout normal avec p à faire varier et dropout channel. La durée de l'entrainement explose mais j'obtiens de bien meilleurs résultats à la fin pour dropout(0.2) -> j'arrive à 76% \n",
        "\n",
        "Enfin, dernière, technique, je fais la moyenne des prédictions sur 6 modèles et j'arrive à 77% de val."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3NYlDtaL5gT"
      },
      "source": [
        "Idées sur le modèle :     \n",
        "- Mettre du Dropout, drop block ou drop filter ou drop connect ou stockastic depth\n",
        "- Simplifier le modèle \n",
        "- changer MaxPooling en AveragePooling \n",
        "- Augmenter taille avant MaxPooling : ne fonctionne pas \n",
        "\n",
        "\n",
        "Une fois que modèle choisi :     \n",
        "- Faire du label smoothing -> gagne 3% sur mobilenet3 \n",
        "    0.1 : mieux que 1.5\n",
        "- Déséquilibrer la loss \n",
        "- Augmenter le nb de données des grosses classes -> avoir encore plus d'images pour moins overfiter (faire recherches sur la data aug et ses limites)\n",
        "- mettre de la régularisation -> mettre du weight decay sur toutes les couches \n",
        "- Optimizer RMSProp : résultats similaires\n",
        "\n",
        "Pousser l'entrainement à fond :      \n",
        "- Early Stopping \n",
        "- Learning rate : à priori inutile pcq le problème est l'overfitting ici"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4YlqGmabE4C",
        "outputId": "eb683c8f-075a-49ac-e289-5fe9308bd313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "  2/586 [..............................] - ETA: 1:47 - loss: 4.9974 - accuracy: 0.0176WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0810s vs `on_train_batch_end` time: 0.1430s). Check your callbacks.\n",
            "586/586 [==============================] - 113s 193ms/step - loss: 4.2584 - accuracy: 0.0862 - val_loss: 4.7734 - val_accuracy: 0.0200\n",
            "Epoch 2/60\n",
            "586/586 [==============================] - 104s 178ms/step - loss: 3.6181 - accuracy: 0.2191 - val_loss: 3.0884 - val_accuracy: 0.3588\n",
            "Epoch 3/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 3.3602 - accuracy: 0.2829 - val_loss: 2.8105 - val_accuracy: 0.4412\n",
            "Epoch 4/60\n",
            "586/586 [==============================] - 94s 160ms/step - loss: 3.1691 - accuracy: 0.3339 - val_loss: 2.6402 - val_accuracy: 0.4965\n",
            "Epoch 5/60\n",
            "586/586 [==============================] - 93s 158ms/step - loss: 3.0026 - accuracy: 0.3794 - val_loss: 2.4869 - val_accuracy: 0.5329\n",
            "Epoch 6/60\n",
            "586/586 [==============================] - 94s 161ms/step - loss: 2.8763 - accuracy: 0.4148 - val_loss: 2.4250 - val_accuracy: 0.5600\n",
            "Epoch 7/60\n",
            "586/586 [==============================] - 95s 161ms/step - loss: 2.7902 - accuracy: 0.4406 - val_loss: 2.3358 - val_accuracy: 0.5800\n",
            "Epoch 8/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.7219 - accuracy: 0.4602 - val_loss: 2.2749 - val_accuracy: 0.6000\n",
            "Epoch 9/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.6743 - accuracy: 0.4739 - val_loss: 2.2515 - val_accuracy: 0.6188\n",
            "Epoch 10/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.6341 - accuracy: 0.4870 - val_loss: 2.2354 - val_accuracy: 0.6212\n",
            "Epoch 11/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.6011 - accuracy: 0.4972 - val_loss: 2.1879 - val_accuracy: 0.6329\n",
            "Epoch 12/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.5736 - accuracy: 0.5054 - val_loss: 2.1821 - val_accuracy: 0.6365\n",
            "Epoch 13/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.5505 - accuracy: 0.5120 - val_loss: 2.1822 - val_accuracy: 0.6435\n",
            "Epoch 14/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 2.5286 - accuracy: 0.5213 - val_loss: 2.1603 - val_accuracy: 0.6624\n",
            "Epoch 15/60\n",
            "586/586 [==============================] - 96s 163ms/step - loss: 2.5118 - accuracy: 0.5246 - val_loss: 2.1472 - val_accuracy: 0.6482\n",
            "Epoch 16/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.4949 - accuracy: 0.5315 - val_loss: 2.1414 - val_accuracy: 0.6400\n",
            "Epoch 17/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.4784 - accuracy: 0.5358 - val_loss: 2.1421 - val_accuracy: 0.6612\n",
            "Epoch 18/60\n",
            "586/586 [==============================] - 96s 165ms/step - loss: 2.4659 - accuracy: 0.5396 - val_loss: 2.0930 - val_accuracy: 0.6882\n",
            "Epoch 19/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.4545 - accuracy: 0.5429 - val_loss: 2.1251 - val_accuracy: 0.6765\n",
            "Epoch 20/60\n",
            "586/586 [==============================] - 96s 163ms/step - loss: 2.4411 - accuracy: 0.5474 - val_loss: 2.1277 - val_accuracy: 0.6753\n",
            "Epoch 21/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.4301 - accuracy: 0.5520 - val_loss: 2.1013 - val_accuracy: 0.6718\n",
            "Epoch 22/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.4243 - accuracy: 0.5520 - val_loss: 2.1299 - val_accuracy: 0.6718\n",
            "Epoch 23/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.4138 - accuracy: 0.5569 - val_loss: 2.0984 - val_accuracy: 0.6753\n",
            "Epoch 24/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.4041 - accuracy: 0.5595 - val_loss: 2.0891 - val_accuracy: 0.6812\n",
            "Epoch 25/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.3926 - accuracy: 0.5640 - val_loss: 2.0811 - val_accuracy: 0.6859\n",
            "Epoch 26/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 2.3885 - accuracy: 0.5650 - val_loss: 2.0793 - val_accuracy: 0.6647\n",
            "Epoch 27/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.3806 - accuracy: 0.5685 - val_loss: 2.0555 - val_accuracy: 0.6929\n",
            "Epoch 28/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 2.3701 - accuracy: 0.5704 - val_loss: 2.0633 - val_accuracy: 0.6894\n",
            "Epoch 29/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.3652 - accuracy: 0.5717 - val_loss: 2.0433 - val_accuracy: 0.6918\n",
            "Epoch 30/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.3609 - accuracy: 0.5741 - val_loss: 2.0553 - val_accuracy: 0.6859\n",
            "Epoch 31/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.3537 - accuracy: 0.5760 - val_loss: 2.0281 - val_accuracy: 0.6882\n",
            "Epoch 32/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.3470 - accuracy: 0.5793 - val_loss: 2.0680 - val_accuracy: 0.6812\n",
            "Epoch 33/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 2.3388 - accuracy: 0.5815 - val_loss: 2.0546 - val_accuracy: 0.6953\n",
            "Epoch 34/60\n",
            "586/586 [==============================] - 96s 165ms/step - loss: 2.3343 - accuracy: 0.5823 - val_loss: 2.0392 - val_accuracy: 0.7024\n",
            "Epoch 35/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.3262 - accuracy: 0.5845 - val_loss: 2.0586 - val_accuracy: 0.6976\n",
            "Epoch 36/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.3232 - accuracy: 0.5858 - val_loss: 2.0546 - val_accuracy: 0.6953\n",
            "Epoch 37/60\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.3179 - accuracy: 0.5884 - val_loss: 2.0542 - val_accuracy: 0.6976\n",
            "Epoch 38/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 2.3148 - accuracy: 0.5890 - val_loss: 2.0174 - val_accuracy: 0.6976\n",
            "Epoch 39/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 2.3096 - accuracy: 0.5896 - val_loss: 2.0553 - val_accuracy: 0.6941\n",
            "Epoch 40/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 2.3045 - accuracy: 0.5921 - val_loss: 2.0209 - val_accuracy: 0.6953\n",
            "Epoch 41/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 2.2995 - accuracy: 0.5918 - val_loss: 2.0511 - val_accuracy: 0.6976\n",
            "Epoch 42/60\n",
            "586/586 [==============================] - 102s 174ms/step - loss: 2.2964 - accuracy: 0.5959 - val_loss: 2.0197 - val_accuracy: 0.7035\n",
            "Epoch 43/60\n",
            "586/586 [==============================] - 102s 174ms/step - loss: 2.2924 - accuracy: 0.5959 - val_loss: 2.0026 - val_accuracy: 0.7094\n",
            "Epoch 44/60\n",
            "586/586 [==============================] - 103s 176ms/step - loss: 2.2865 - accuracy: 0.5981 - val_loss: 2.0116 - val_accuracy: 0.7094\n",
            "Epoch 45/60\n",
            "586/586 [==============================] - 104s 177ms/step - loss: 2.2797 - accuracy: 0.5999 - val_loss: 2.0288 - val_accuracy: 0.6941\n",
            "Epoch 46/60\n",
            "586/586 [==============================] - 103s 176ms/step - loss: 2.2775 - accuracy: 0.6006 - val_loss: 2.0300 - val_accuracy: 0.6941\n",
            "Epoch 47/60\n",
            "586/586 [==============================] - 102s 174ms/step - loss: 2.2752 - accuracy: 0.6003 - val_loss: 2.0421 - val_accuracy: 0.6953\n",
            "Epoch 48/60\n",
            "586/586 [==============================] - 102s 174ms/step - loss: 2.2729 - accuracy: 0.6013 - val_loss: 2.0511 - val_accuracy: 0.7035\n",
            "Epoch 49/60\n",
            "586/586 [==============================] - 102s 175ms/step - loss: 2.2680 - accuracy: 0.6034 - val_loss: 2.0228 - val_accuracy: 0.6941\n",
            "Epoch 50/60\n",
            "586/586 [==============================] - 102s 173ms/step - loss: 2.2629 - accuracy: 0.6049 - val_loss: 2.0065 - val_accuracy: 0.7047\n",
            "Epoch 51/60\n",
            "586/586 [==============================] - 101s 172ms/step - loss: 2.2626 - accuracy: 0.6057 - val_loss: 2.0320 - val_accuracy: 0.6976\n",
            "Epoch 52/60\n",
            "586/586 [==============================] - 101s 173ms/step - loss: 2.2595 - accuracy: 0.6060 - val_loss: 2.0003 - val_accuracy: 0.7118\n",
            "Epoch 53/60\n",
            "586/586 [==============================] - 99s 170ms/step - loss: 2.2566 - accuracy: 0.6073 - val_loss: 1.9920 - val_accuracy: 0.7059\n",
            "Epoch 54/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.2514 - accuracy: 0.6091 - val_loss: 2.0023 - val_accuracy: 0.7094\n",
            "Epoch 55/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.2498 - accuracy: 0.6095 - val_loss: 1.9917 - val_accuracy: 0.7071\n",
            "Epoch 56/60\n",
            "586/586 [==============================] - 98s 167ms/step - loss: 2.2459 - accuracy: 0.6101 - val_loss: 2.0237 - val_accuracy: 0.7000\n",
            "Epoch 57/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.2443 - accuracy: 0.6104 - val_loss: 2.0150 - val_accuracy: 0.7012\n",
            "Epoch 58/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.2383 - accuracy: 0.6132 - val_loss: 1.9706 - val_accuracy: 0.7165\n",
            "Epoch 59/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.2363 - accuracy: 0.6133 - val_loss: 1.9630 - val_accuracy: 0.7212\n",
            "Epoch 60/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 2.2339 - accuracy: 0.6158 - val_loss: 1.9949 - val_accuracy: 0.7012\n"
          ]
        }
      ],
      "source": [
        "# Reduce LR on plateau is not relevant as the model always overfits\n",
        "\n",
        "# rlr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "#     monitor='val_loss', factor=0.7, patience=3, verbose=0,\n",
        "#     mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "\n",
        "# opt = tf.keras.optimizers.RMSprop(\n",
        "#     learning_rate=0.045,\n",
        "#     rho=0.9,\n",
        "#     momentum=0.9,\n",
        "#     epsilon=1e-07,\n",
        "#     centered=False,\n",
        "#     name=\"RMSprop\")\n",
        "\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "model.compile(optimizer=opt, \n",
        "              loss=loss, \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpoint_filepath = 'weights.{epoch:02d}-{val_accuracy:.4f}.h5'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "#model.load_weights('file')\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 256 ,epochs=60,validation_data=(x_test,y_test),callbacks = [model_checkpoint_callback])\n",
        "#history = model.fit(x_train[:2], y_train[:2], batch_size = 2 ,epochs=10000,validation_data=(x_train[:2], y_train[:2]),callbacks = [rlr])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "586/586 [==============================] - 107s 182ms/step - loss: 1.8737 - accuracy: 0.7224 - val_loss: 1.8457 - val_accuracy: 0.7600\n",
            "Epoch 2/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8525 - accuracy: 0.7273 - val_loss: 1.8364 - val_accuracy: 0.7482\n",
            "Epoch 3/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 1.8442 - accuracy: 0.7293 - val_loss: 1.8232 - val_accuracy: 0.7529\n",
            "Epoch 4/60\n",
            "586/586 [==============================] - 96s 165ms/step - loss: 1.8386 - accuracy: 0.7315 - val_loss: 1.8801 - val_accuracy: 0.7141\n",
            "Epoch 5/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 1.8351 - accuracy: 0.7324 - val_loss: 1.8211 - val_accuracy: 0.7588\n",
            "Epoch 6/60\n",
            "586/586 [==============================] - 97s 165ms/step - loss: 1.8328 - accuracy: 0.7331 - val_loss: 1.8564 - val_accuracy: 0.7600\n",
            "Epoch 7/60\n",
            "586/586 [==============================] - 96s 165ms/step - loss: 1.8282 - accuracy: 0.7331 - val_loss: 1.8705 - val_accuracy: 0.7529\n",
            "Epoch 8/60\n",
            "586/586 [==============================] - 97s 166ms/step - loss: 1.8254 - accuracy: 0.7363 - val_loss: 1.8436 - val_accuracy: 0.7624\n",
            "Epoch 9/60\n",
            "586/586 [==============================] - 99s 170ms/step - loss: 1.8257 - accuracy: 0.7348 - val_loss: 1.8449 - val_accuracy: 0.7482\n",
            "Epoch 10/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8206 - accuracy: 0.7379 - val_loss: 1.8476 - val_accuracy: 0.7506\n",
            "Epoch 11/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.8224 - accuracy: 0.7360 - val_loss: 1.8332 - val_accuracy: 0.7565\n",
            "Epoch 12/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8193 - accuracy: 0.7366 - val_loss: 1.8479 - val_accuracy: 0.7576\n",
            "Epoch 13/60\n",
            "586/586 [==============================] - 101s 172ms/step - loss: 1.8177 - accuracy: 0.7378 - val_loss: 1.8769 - val_accuracy: 0.7506\n",
            "Epoch 14/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.8168 - accuracy: 0.7369 - val_loss: 1.8254 - val_accuracy: 0.7624\n",
            "Epoch 15/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.8122 - accuracy: 0.7389 - val_loss: 1.8275 - val_accuracy: 0.7624\n",
            "Epoch 16/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8130 - accuracy: 0.7384 - val_loss: 1.8695 - val_accuracy: 0.7353\n",
            "Epoch 17/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8081 - accuracy: 0.7409 - val_loss: 1.8456 - val_accuracy: 0.7388\n",
            "Epoch 18/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8116 - accuracy: 0.7395 - val_loss: 1.8286 - val_accuracy: 0.7635\n",
            "Epoch 19/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8057 - accuracy: 0.7411 - val_loss: 1.8782 - val_accuracy: 0.7376\n",
            "Epoch 20/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8056 - accuracy: 0.7415 - val_loss: 1.8426 - val_accuracy: 0.7471\n",
            "Epoch 21/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8084 - accuracy: 0.7404 - val_loss: 1.8537 - val_accuracy: 0.7400\n",
            "Epoch 22/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8073 - accuracy: 0.7406 - val_loss: 1.8679 - val_accuracy: 0.7471\n",
            "Epoch 23/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8037 - accuracy: 0.7417 - val_loss: 1.8480 - val_accuracy: 0.7388\n",
            "Epoch 24/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.8036 - accuracy: 0.7427 - val_loss: 1.8613 - val_accuracy: 0.7282\n",
            "Epoch 25/60\n",
            "586/586 [==============================] - 101s 172ms/step - loss: 1.8029 - accuracy: 0.7432 - val_loss: 1.8425 - val_accuracy: 0.7388\n",
            "Epoch 26/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.8014 - accuracy: 0.7439 - val_loss: 1.8357 - val_accuracy: 0.7506\n",
            "Epoch 27/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 1.8021 - accuracy: 0.7419 - val_loss: 1.9685 - val_accuracy: 0.6929\n",
            "Epoch 28/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.7995 - accuracy: 0.7435 - val_loss: 1.8419 - val_accuracy: 0.7494\n",
            "Epoch 29/60\n",
            "586/586 [==============================] - 100s 171ms/step - loss: 1.7981 - accuracy: 0.7437 - val_loss: 1.8263 - val_accuracy: 0.7506\n",
            "Epoch 30/60\n",
            "586/586 [==============================] - 100s 170ms/step - loss: 1.7970 - accuracy: 0.7451 - val_loss: 1.8656 - val_accuracy: 0.7400\n",
            "Epoch 31/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 1.7965 - accuracy: 0.7426 - val_loss: 1.9462 - val_accuracy: 0.7188\n",
            "Epoch 32/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 1.7959 - accuracy: 0.7442 - val_loss: 1.8552 - val_accuracy: 0.7576\n",
            "Epoch 33/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 1.7942 - accuracy: 0.7463 - val_loss: 1.8744 - val_accuracy: 0.7600\n",
            "Epoch 34/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 1.7957 - accuracy: 0.7451 - val_loss: 1.8597 - val_accuracy: 0.7576\n",
            "Epoch 35/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7943 - accuracy: 0.7445 - val_loss: 1.8227 - val_accuracy: 0.7612\n",
            "Epoch 36/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7921 - accuracy: 0.7463 - val_loss: 1.8376 - val_accuracy: 0.7565\n",
            "Epoch 37/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7927 - accuracy: 0.7445 - val_loss: 1.8535 - val_accuracy: 0.7565\n",
            "Epoch 38/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7907 - accuracy: 0.7464 - val_loss: 1.8156 - val_accuracy: 0.7565\n",
            "Epoch 39/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 1.7891 - accuracy: 0.7465 - val_loss: 1.8362 - val_accuracy: 0.7659\n",
            "Epoch 40/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7909 - accuracy: 0.7472 - val_loss: 1.8443 - val_accuracy: 0.7518\n",
            "Epoch 41/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7896 - accuracy: 0.7475 - val_loss: 1.8830 - val_accuracy: 0.7447\n",
            "Epoch 42/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7872 - accuracy: 0.7471 - val_loss: 1.8378 - val_accuracy: 0.7565\n",
            "Epoch 43/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7909 - accuracy: 0.7465 - val_loss: 1.8414 - val_accuracy: 0.7353\n",
            "Epoch 44/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7853 - accuracy: 0.7475 - val_loss: 1.8436 - val_accuracy: 0.7506\n",
            "Epoch 45/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7865 - accuracy: 0.7485 - val_loss: 1.8659 - val_accuracy: 0.7541\n",
            "Epoch 46/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7865 - accuracy: 0.7481 - val_loss: 1.8200 - val_accuracy: 0.7529\n",
            "Epoch 47/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 1.7843 - accuracy: 0.7489 - val_loss: 1.8656 - val_accuracy: 0.7565\n",
            "Epoch 48/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7864 - accuracy: 0.7488 - val_loss: 1.8451 - val_accuracy: 0.7518\n",
            "Epoch 49/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7860 - accuracy: 0.7476 - val_loss: 1.8448 - val_accuracy: 0.7612\n",
            "Epoch 50/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7835 - accuracy: 0.7484 - val_loss: 1.8482 - val_accuracy: 0.7588\n",
            "Epoch 51/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7834 - accuracy: 0.7480 - val_loss: 1.8334 - val_accuracy: 0.7588\n",
            "Epoch 52/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7828 - accuracy: 0.7483 - val_loss: 2.1004 - val_accuracy: 0.6671\n",
            "Epoch 53/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7817 - accuracy: 0.7498 - val_loss: 1.8463 - val_accuracy: 0.7576\n",
            "Epoch 54/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7826 - accuracy: 0.7484 - val_loss: 1.8357 - val_accuracy: 0.7506\n",
            "Epoch 55/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7805 - accuracy: 0.7495 - val_loss: 1.8532 - val_accuracy: 0.7424\n",
            "Epoch 56/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 1.7788 - accuracy: 0.7502 - val_loss: 1.8244 - val_accuracy: 0.7659\n",
            "Epoch 57/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7783 - accuracy: 0.7502 - val_loss: 1.8668 - val_accuracy: 0.7435\n",
            "Epoch 58/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 1.7789 - accuracy: 0.7501 - val_loss: 1.8110 - val_accuracy: 0.7553\n",
            "Epoch 59/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7769 - accuracy: 0.7504 - val_loss: 1.8412 - val_accuracy: 0.7600\n",
            "Epoch 60/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 1.7770 - accuracy: 0.7511 - val_loss: 1.8443 - val_accuracy: 0.7506\n",
            "Epoch 1/60\n",
            "586/586 [==============================] - 101s 173ms/step - loss: 2.1031 - accuracy: 0.6509 - val_loss: 1.9235 - val_accuracy: 0.7341\n",
            "Epoch 2/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0914 - accuracy: 0.6523 - val_loss: 1.9122 - val_accuracy: 0.7318\n",
            "Epoch 3/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0874 - accuracy: 0.6547 - val_loss: 1.9012 - val_accuracy: 0.7412\n",
            "Epoch 4/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0805 - accuracy: 0.6566 - val_loss: 1.9113 - val_accuracy: 0.7235\n",
            "Epoch 5/60\n",
            "586/586 [==============================] - 99s 169ms/step - loss: 2.0760 - accuracy: 0.6591 - val_loss: 1.9135 - val_accuracy: 0.7365\n",
            "Epoch 6/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0782 - accuracy: 0.6581 - val_loss: 1.9296 - val_accuracy: 0.7353\n",
            "Epoch 7/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0733 - accuracy: 0.6587 - val_loss: 1.9073 - val_accuracy: 0.7376\n",
            "Epoch 8/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0729 - accuracy: 0.6585 - val_loss: 1.9141 - val_accuracy: 0.7365\n",
            "Epoch 9/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0712 - accuracy: 0.6582 - val_loss: 1.9253 - val_accuracy: 0.7176\n",
            "Epoch 10/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0707 - accuracy: 0.6598 - val_loss: 1.9221 - val_accuracy: 0.7224\n",
            "Epoch 11/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0700 - accuracy: 0.6594 - val_loss: 1.9588 - val_accuracy: 0.7153\n",
            "Epoch 12/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0669 - accuracy: 0.6594 - val_loss: 1.9274 - val_accuracy: 0.7306\n",
            "Epoch 13/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0659 - accuracy: 0.6600 - val_loss: 1.9581 - val_accuracy: 0.7118\n",
            "Epoch 14/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0658 - accuracy: 0.6606 - val_loss: 1.9192 - val_accuracy: 0.7388\n",
            "Epoch 15/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0638 - accuracy: 0.6616 - val_loss: 1.9361 - val_accuracy: 0.7212\n",
            "Epoch 16/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0659 - accuracy: 0.6599 - val_loss: 1.9081 - val_accuracy: 0.7259\n",
            "Epoch 17/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0605 - accuracy: 0.6615 - val_loss: 1.8947 - val_accuracy: 0.7376\n",
            "Epoch 18/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0580 - accuracy: 0.6621 - val_loss: 1.9211 - val_accuracy: 0.7471\n",
            "Epoch 19/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0613 - accuracy: 0.6617 - val_loss: 1.9229 - val_accuracy: 0.7365\n",
            "Epoch 20/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0585 - accuracy: 0.6628 - val_loss: 1.9346 - val_accuracy: 0.7200\n",
            "Epoch 21/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0578 - accuracy: 0.6634 - val_loss: 1.9406 - val_accuracy: 0.7188\n",
            "Epoch 22/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0555 - accuracy: 0.6638 - val_loss: 1.9655 - val_accuracy: 0.7176\n",
            "Epoch 23/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0599 - accuracy: 0.6618 - val_loss: 1.9366 - val_accuracy: 0.7200\n",
            "Epoch 24/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0579 - accuracy: 0.6626 - val_loss: 1.9422 - val_accuracy: 0.7224\n",
            "Epoch 25/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0524 - accuracy: 0.6639 - val_loss: 1.9287 - val_accuracy: 0.7271\n",
            "Epoch 26/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0527 - accuracy: 0.6646 - val_loss: 1.9064 - val_accuracy: 0.7318\n",
            "Epoch 27/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0538 - accuracy: 0.6632 - val_loss: 1.9179 - val_accuracy: 0.7224\n",
            "Epoch 28/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0529 - accuracy: 0.6639 - val_loss: 1.9127 - val_accuracy: 0.7306\n",
            "Epoch 29/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0513 - accuracy: 0.6638 - val_loss: 1.9116 - val_accuracy: 0.7400\n",
            "Epoch 30/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0521 - accuracy: 0.6652 - val_loss: 1.9208 - val_accuracy: 0.7200\n",
            "Epoch 31/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0521 - accuracy: 0.6653 - val_loss: 1.9394 - val_accuracy: 0.7329\n",
            "Epoch 32/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0495 - accuracy: 0.6665 - val_loss: 1.9746 - val_accuracy: 0.7153\n",
            "Epoch 33/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0516 - accuracy: 0.6641 - val_loss: 1.9056 - val_accuracy: 0.7365\n",
            "Epoch 34/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0502 - accuracy: 0.6650 - val_loss: 1.9028 - val_accuracy: 0.7353\n",
            "Epoch 35/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0471 - accuracy: 0.6650 - val_loss: 1.9339 - val_accuracy: 0.7294\n",
            "Epoch 36/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0464 - accuracy: 0.6662 - val_loss: 1.9191 - val_accuracy: 0.7376\n",
            "Epoch 37/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0450 - accuracy: 0.6668 - val_loss: 1.9124 - val_accuracy: 0.7212\n",
            "Epoch 38/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0473 - accuracy: 0.6675 - val_loss: 1.8726 - val_accuracy: 0.7482\n",
            "Epoch 39/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0444 - accuracy: 0.6677 - val_loss: 1.9165 - val_accuracy: 0.7294\n",
            "Epoch 40/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0492 - accuracy: 0.6658 - val_loss: 1.9578 - val_accuracy: 0.7259\n",
            "Epoch 41/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0457 - accuracy: 0.6663 - val_loss: 1.8974 - val_accuracy: 0.7459\n",
            "Epoch 42/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0429 - accuracy: 0.6678 - val_loss: 1.9141 - val_accuracy: 0.7341\n",
            "Epoch 43/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0442 - accuracy: 0.6667 - val_loss: 1.9021 - val_accuracy: 0.7247\n",
            "Epoch 44/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0440 - accuracy: 0.6673 - val_loss: 1.9247 - val_accuracy: 0.7435\n",
            "Epoch 45/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0446 - accuracy: 0.6672 - val_loss: 1.9000 - val_accuracy: 0.7329\n",
            "Epoch 46/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0417 - accuracy: 0.6685 - val_loss: 1.9454 - val_accuracy: 0.7176\n",
            "Epoch 47/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0421 - accuracy: 0.6675 - val_loss: 1.9150 - val_accuracy: 0.7224\n",
            "Epoch 48/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0429 - accuracy: 0.6665 - val_loss: 1.9086 - val_accuracy: 0.7318\n",
            "Epoch 49/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0424 - accuracy: 0.6671 - val_loss: 1.9068 - val_accuracy: 0.7388\n",
            "Epoch 50/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0400 - accuracy: 0.6700 - val_loss: 1.9113 - val_accuracy: 0.7294\n",
            "Epoch 51/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0396 - accuracy: 0.6688 - val_loss: 1.8931 - val_accuracy: 0.7353\n",
            "Epoch 52/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0416 - accuracy: 0.6691 - val_loss: 1.8975 - val_accuracy: 0.7353\n",
            "Epoch 53/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0373 - accuracy: 0.6693 - val_loss: 1.9444 - val_accuracy: 0.7224\n",
            "Epoch 54/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0383 - accuracy: 0.6694 - val_loss: 1.9054 - val_accuracy: 0.7259\n",
            "Epoch 55/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0382 - accuracy: 0.6696 - val_loss: 1.9462 - val_accuracy: 0.7212\n",
            "Epoch 56/60\n",
            "586/586 [==============================] - 99s 168ms/step - loss: 2.0400 - accuracy: 0.6684 - val_loss: 1.9227 - val_accuracy: 0.7306\n",
            "Epoch 57/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0385 - accuracy: 0.6691 - val_loss: 1.9033 - val_accuracy: 0.7247\n",
            "Epoch 58/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0387 - accuracy: 0.6693 - val_loss: 1.9137 - val_accuracy: 0.7306\n",
            "Epoch 59/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0367 - accuracy: 0.6702 - val_loss: 1.9100 - val_accuracy: 0.7435\n",
            "Epoch 60/60\n",
            "586/586 [==============================] - 98s 168ms/step - loss: 2.0348 - accuracy: 0.6712 - val_loss: 1.8927 - val_accuracy: 0.7318\n",
            "Epoch 1/60\n",
            "  2/586 [..............................] - ETA: 1:40 - loss: 2.1863 - accuracy: 0.6133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0650s vs `on_train_batch_end` time: 0.1371s). Check your callbacks.\n",
            "586/586 [==============================] - 96s 164ms/step - loss: 2.2008 - accuracy: 0.6280 - val_loss: 1.9537 - val_accuracy: 0.7306\n",
            "Epoch 2/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1835 - accuracy: 0.6333 - val_loss: 1.9535 - val_accuracy: 0.7012\n",
            "Epoch 3/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1722 - accuracy: 0.6360 - val_loss: 1.9359 - val_accuracy: 0.7235\n",
            "Epoch 4/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1634 - accuracy: 0.6377 - val_loss: 1.9292 - val_accuracy: 0.7176\n",
            "Epoch 5/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1593 - accuracy: 0.6384 - val_loss: 1.9365 - val_accuracy: 0.7212\n",
            "Epoch 6/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1549 - accuracy: 0.6400 - val_loss: 1.9488 - val_accuracy: 0.7188\n",
            "Epoch 7/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1505 - accuracy: 0.6408 - val_loss: 1.9430 - val_accuracy: 0.7188\n",
            "Epoch 8/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1466 - accuracy: 0.6417 - val_loss: 1.9348 - val_accuracy: 0.7224\n",
            "Epoch 9/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1447 - accuracy: 0.6425 - val_loss: 1.9252 - val_accuracy: 0.7129\n",
            "Epoch 10/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1424 - accuracy: 0.6433 - val_loss: 1.9353 - val_accuracy: 0.7353\n",
            "Epoch 11/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1379 - accuracy: 0.6450 - val_loss: 1.9101 - val_accuracy: 0.7271\n",
            "Epoch 12/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1371 - accuracy: 0.6454 - val_loss: 1.9310 - val_accuracy: 0.7259\n",
            "Epoch 13/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1342 - accuracy: 0.6467 - val_loss: 1.9136 - val_accuracy: 0.7447\n",
            "Epoch 14/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1337 - accuracy: 0.6463 - val_loss: 1.9100 - val_accuracy: 0.7353\n",
            "Epoch 15/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1315 - accuracy: 0.6472 - val_loss: 1.9345 - val_accuracy: 0.7200\n",
            "Epoch 16/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1297 - accuracy: 0.6478 - val_loss: 1.9262 - val_accuracy: 0.7212\n",
            "Epoch 17/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1273 - accuracy: 0.6478 - val_loss: 1.9430 - val_accuracy: 0.7318\n",
            "Epoch 18/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1273 - accuracy: 0.6487 - val_loss: 1.9423 - val_accuracy: 0.7247\n",
            "Epoch 19/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1273 - accuracy: 0.6468 - val_loss: 1.9382 - val_accuracy: 0.7235\n",
            "Epoch 20/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1204 - accuracy: 0.6491 - val_loss: 1.9331 - val_accuracy: 0.7306\n",
            "Epoch 21/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1219 - accuracy: 0.6493 - val_loss: 1.9521 - val_accuracy: 0.7318\n",
            "Epoch 22/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1203 - accuracy: 0.6505 - val_loss: 1.9200 - val_accuracy: 0.7224\n",
            "Epoch 23/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1177 - accuracy: 0.6514 - val_loss: 1.9284 - val_accuracy: 0.7235\n",
            "Epoch 24/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1146 - accuracy: 0.6522 - val_loss: 1.9235 - val_accuracy: 0.7176\n",
            "Epoch 25/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1173 - accuracy: 0.6508 - val_loss: 1.9244 - val_accuracy: 0.7306\n",
            "Epoch 26/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1138 - accuracy: 0.6520 - val_loss: 1.8967 - val_accuracy: 0.7424\n",
            "Epoch 27/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1142 - accuracy: 0.6512 - val_loss: 1.9088 - val_accuracy: 0.7365\n",
            "Epoch 28/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1118 - accuracy: 0.6524 - val_loss: 1.9285 - val_accuracy: 0.7435\n",
            "Epoch 29/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1098 - accuracy: 0.6529 - val_loss: 1.9378 - val_accuracy: 0.7282\n",
            "Epoch 30/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1080 - accuracy: 0.6541 - val_loss: 1.9220 - val_accuracy: 0.7212\n",
            "Epoch 31/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1077 - accuracy: 0.6533 - val_loss: 1.9179 - val_accuracy: 0.7271\n",
            "Epoch 32/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1091 - accuracy: 0.6532 - val_loss: 1.9218 - val_accuracy: 0.7282\n",
            "Epoch 33/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1055 - accuracy: 0.6537 - val_loss: 1.8969 - val_accuracy: 0.7388\n",
            "Epoch 34/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1049 - accuracy: 0.6543 - val_loss: 1.8974 - val_accuracy: 0.7318\n",
            "Epoch 35/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1025 - accuracy: 0.6549 - val_loss: 1.9061 - val_accuracy: 0.7353\n",
            "Epoch 36/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1025 - accuracy: 0.6547 - val_loss: 1.9009 - val_accuracy: 0.7353\n",
            "Epoch 37/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1021 - accuracy: 0.6552 - val_loss: 1.8882 - val_accuracy: 0.7435\n",
            "Epoch 38/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.1020 - accuracy: 0.6546 - val_loss: 1.9218 - val_accuracy: 0.7482\n",
            "Epoch 39/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1000 - accuracy: 0.6556 - val_loss: 1.9089 - val_accuracy: 0.7329\n",
            "Epoch 40/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.1021 - accuracy: 0.6559 - val_loss: 1.9034 - val_accuracy: 0.7353\n",
            "Epoch 41/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0961 - accuracy: 0.6573 - val_loss: 1.9100 - val_accuracy: 0.7424\n",
            "Epoch 42/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0966 - accuracy: 0.6567 - val_loss: 1.9131 - val_accuracy: 0.7435\n",
            "Epoch 43/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0963 - accuracy: 0.6582 - val_loss: 1.9162 - val_accuracy: 0.7353\n",
            "Epoch 44/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0946 - accuracy: 0.6573 - val_loss: 1.9137 - val_accuracy: 0.7247\n",
            "Epoch 45/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0953 - accuracy: 0.6582 - val_loss: 1.9048 - val_accuracy: 0.7471\n",
            "Epoch 46/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0909 - accuracy: 0.6582 - val_loss: 1.8860 - val_accuracy: 0.7353\n",
            "Epoch 47/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0933 - accuracy: 0.6587 - val_loss: 1.9071 - val_accuracy: 0.7365\n",
            "Epoch 48/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.0914 - accuracy: 0.6603 - val_loss: 1.8968 - val_accuracy: 0.7494\n",
            "Epoch 49/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0912 - accuracy: 0.6580 - val_loss: 1.9131 - val_accuracy: 0.7365\n",
            "Epoch 50/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0929 - accuracy: 0.6572 - val_loss: 1.8973 - val_accuracy: 0.7376\n",
            "Epoch 51/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0905 - accuracy: 0.6587 - val_loss: 1.9022 - val_accuracy: 0.7388\n",
            "Epoch 52/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0868 - accuracy: 0.6599 - val_loss: 1.9093 - val_accuracy: 0.7400\n",
            "Epoch 53/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0890 - accuracy: 0.6600 - val_loss: 1.9234 - val_accuracy: 0.7306\n",
            "Epoch 54/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0867 - accuracy: 0.6594 - val_loss: 1.9198 - val_accuracy: 0.7235\n",
            "Epoch 55/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0881 - accuracy: 0.6594 - val_loss: 1.9170 - val_accuracy: 0.7494\n",
            "Epoch 56/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0856 - accuracy: 0.6612 - val_loss: 1.8828 - val_accuracy: 0.7353\n",
            "Epoch 57/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0860 - accuracy: 0.6584 - val_loss: 1.9036 - val_accuracy: 0.7318\n",
            "Epoch 58/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0839 - accuracy: 0.6613 - val_loss: 1.8929 - val_accuracy: 0.7247\n",
            "Epoch 59/60\n",
            "586/586 [==============================] - 95s 162ms/step - loss: 2.0822 - accuracy: 0.6613 - val_loss: 1.9199 - val_accuracy: 0.7306\n",
            "Epoch 60/60\n",
            "586/586 [==============================] - 95s 163ms/step - loss: 2.0821 - accuracy: 0.6614 - val_loss: 1.9030 - val_accuracy: 0.7318\n"
          ]
        }
      ],
      "source": [
        "### Resume the training of multiple models\n",
        "\n",
        "create_model = [mobile5,mobile6,mobile7]\n",
        "previous = ['last_mob5_120.h5',\"last_mob6_120.h5\",\"last_mob7_120.h5\"]\n",
        "name = [\"mob5\",\"mob6\",\"mob7\"]\n",
        "\n",
        "for i in range(len(create_model)):\n",
        "    model = create_model[i]()\n",
        "    opt = tf.keras.optimizers.Adam()\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "    model.compile(optimizer=opt, \n",
        "                loss=loss, \n",
        "                metrics=['accuracy'])\n",
        "    model.load_weights(previous[i])\n",
        "    checkpoint_filepath = name[i]+'.120+{epoch:02d}-{val_accuracy:.4f}-{accuracy:.4f}.h5'\n",
        "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "    history = model.fit(x_train, y_train, batch_size = 256 ,epochs=60,validation_data=(x_test,y_test),callbacks = [model_checkpoint_callback])\n",
        "    model.save_weights('last_'+name[i]+'_180.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_pred(y_pred,y_test):\n",
        "    eq = tf.math.equal(tf.argmax(y_pred,axis=-1),tf.argmax(y_test,axis=-1)) \n",
        "    acc = tf.reduce_sum(tf.cast(eq,tf.float32))/tf.cast(tf.shape(y_test)[0],tf.float32)\n",
        "    print(acc.numpy())\n",
        "\n",
        "evaluate_pred(model(x_test,training=False),y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Self Supervised Learning with noisy student learning\n",
        "\n",
        "As there are 100,000 test data that are unlabeled, we can use it to have more training samples. To do that, I used my current best model to generate pseudo-labels and then only retained the predictions with the highest confidence score. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating pseudo labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([100000], shape=(1,), dtype=int32)\n",
            "[42 53  9 ... 77  2 49]\n"
          ]
        }
      ],
      "source": [
        "y_pred = model(x_compet, training=False)\n",
        "pseudo_labels = tf.argmax(y_pred,axis=-1)\n",
        "pseudo_labels= np.array(pseudo_labels)\n",
        "y_pred = np.array(y_pred)\n",
        "\n",
        "print(tf.shape(pseudo_labels))\n",
        "print(pseudo_labels)\n",
        "\n",
        "np.save(\"pseudo_labels\", pseudo_labels)\n",
        "np.save(\"pseudo_pred\", y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization of pseudo labels distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(77895, 28, 28, 1)\n",
            "(77895,)\n"
          ]
        }
      ],
      "source": [
        "pred = np.load(\"pseudo_pred.npy\")\n",
        "pseudo_labels = np.load(\"pseudo_labels.npy\")\n",
        "\n",
        "pred = np.max(pred, axis=-1)\n",
        "\n",
        "plt.hist(pseudo_labels, bins=range(102))\n",
        "plt.show()\n",
        "\n",
        "plt.hist(pred,bins = 100)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creation of the new augmented dataset containing pseudo labels\n",
        "\n",
        "Random augmentation is until 4,000 images in each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train2 = x_compet[pred>0.4]\n",
        "y_train2 = pseudo_labels[pred>0.4]\n",
        "\n",
        "print(np.shape(x_train2))\n",
        "print(np.shape(y_train2))\n",
        "\n",
        "x_train_tot = np.concatenate((x_train,x_train2))\n",
        "y_train_tot = np.concatenate((y_train,y_train2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[329, 200, 514, 585, 634, 941, 606, 677, 337, 898, 343, 778, 790, 662, 767, 506, 686, 632, 836, 753, 950, 985, 1133, 1134, 1119, 380, 971, 728, 1139, 1194, 1176, 524, 964, 895, 1083, 1289, 925, 1238, 1083, 1179, 1073, 935, 1387, 1246, 1204, 1313, 1189, 1411, 1478, 1328, 1405, 1374, 1197, 1833, 1502, 1291, 1478, 1686, 1439, 1668, 1393, 1086, 1591, 1366, 1569, 1530, 1754, 1303, 1575, 1662, 1179, 1545, 1636, 1316, 1702, 1670, 1625, 1610, 1638, 1746, 1735, 1742, 1669, 1735, 1825, 1711, 1640, 1848, 1948, 1896, 1786, 1840, 1986, 1936, 1922, 1762, 1826, 1872, 2427, 1943]\n"
          ]
        }
      ],
      "source": [
        "number = [np.sum(y_train_tot==i) for i in range(100)]\n",
        "print(number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rotation_range=30,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=False,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "#train_datagen.random_transform(image) pour appliquer une transfo\n",
        "#image doit être de la forme (28,28,1)\n",
        "\n",
        "# perform data augmentation\n",
        "# data aug pour tripler le nombre d'images de chaque classe \n",
        "data = [x_train_tot[y_train_tot == i] for i in range(100)]\n",
        "for ind in range(len(data)) :\n",
        "    #print(ind)\n",
        "    clas = data[ind]\n",
        "    nb_base = np.shape(clas)[0]\n",
        "    for _ in range(4000-np.shape(clas)[0]):\n",
        "        nb = np.random.randint(0,nb_base)\n",
        "        image = clas[nb]\n",
        "        new_im = train_datagen.random_transform(image)\n",
        "        data[ind] = np.append(data[ind],[new_im],axis=0)\n",
        "y_train_tot = np.array([i for i in range(len(data)) for j in range(len(data[i]))])\n",
        "x_train_tot = np.concatenate(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_tot = to_categorical(y_train_tot)\n",
        "x_train_tot = x_train_tot / 255 - 0.5 # centering\n",
        "y_test = to_categorical(y_test)\n",
        "x_test = x_test / 255 - 0.5\n",
        "x_compet = x_compet/ 255 - 0.5\n",
        "\n",
        "def shuffle_arrays(x_train,y_train):\n",
        "    p = np.random.permutation(len(x_train))\n",
        "    return x_train[p],y_train[p]\n",
        "x_train_tot,y_train_tot = shuffle_arrays(x_train_tot,y_train_tot)\n",
        "x_test,y_test = shuffle_arrays(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\cleme\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py:5907: random_binomial (from tensorflow.python.keras.backend) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.backend.random_bernoulli` instead.\n",
            "Epoch 1/60\n",
            "600/600 [==============================] - 157s 262ms/step - loss: 4.4157 - accuracy: 0.0636 - val_loss: 4.0968 - val_accuracy: 0.1106\n",
            "Epoch 2/60\n",
            "600/600 [==============================] - 153s 255ms/step - loss: 3.6695 - accuracy: 0.1990 - val_loss: 3.5790 - val_accuracy: 0.2624\n",
            "Epoch 3/60\n",
            "362/600 [=================>............] - ETA: 1:00 - loss: 3.4273 - accuracy: 0.2596"
          ]
        }
      ],
      "source": [
        "### Training\n",
        "\n",
        "create_model = [mobile_big]\n",
        "#previous = ['mobile_big.37-0.7247-0.7180.h5']\n",
        "name = [\"mobile_big\"]\n",
        "\n",
        "for i in range(len(create_model)):\n",
        "    model = create_model[i]()\n",
        "    opt = tf.keras.optimizers.Adam()\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "    model.compile(optimizer=opt, \n",
        "                loss=loss, \n",
        "                metrics=['accuracy'])\n",
        "    #model.load_weights(previous[i])\n",
        "    checkpoint_filepath = name[i]+'.{epoch:02d}-{val_accuracy:.4f}-{accuracy:.4f}.h5'\n",
        "    model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "\n",
        "    history = model.fit(x_train_tot, y_train_tot, batch_size = 256 ,epochs=60,validation_data=(x_test,y_test),callbacks = [model_checkpoint_callback],initial_epoch=0,steps_per_epoch=600)\n",
        "    model.save_weights('last_'+name[i]+'_60.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Des pistes en plus \n",
        "\n",
        "- avoir Trois modèles côte à côte et faire du dropout 0.3 au bout des trois pour en entrainer 1 seul à chaque fois\n",
        "- LDA après MaxPooling \n",
        "- mettre des Denses sur trois modèles non entrainables pour trouver la meilleure régression (retirer le softmax ou pas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MobileNet as a Features extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Linear Discriminant analysis mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck (Bottleneck)      (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_1 (Bottleneck)    (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_2 (Bottleneck)    (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_3 (Bottleneck)    (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_4 (Bottleneck)    (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_5 (Bottleneck)    (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_6 (Bottleneck)    (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Softmax (TensorF [(None, 100)]             0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 303,020\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "import sklearn.ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck (Bottleneck)      (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_1 (Bottleneck)    (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_2 (Bottleneck)    (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_3 (Bottleneck)    (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_4 (Bottleneck)    (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_5 (Bottleneck)    (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_6 (Bottleneck)    (None, 2, 2, 160)         158560    \n",
            "=================================================================\n",
            "Total params: 293,384\n",
            "Trainable params: 286,920\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "output_max_pool = model.get_layer(\"bottleneck_6\").output\n",
        "trunc_model = Model(inputs=model.inputs,outputs=output_max_pool)\n",
        "trunc_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150000, 640)\n",
            "(850, 640)\n"
          ]
        }
      ],
      "source": [
        "train_features = np.reshape(trunc_model.predict(x_train),(150000,-1))\n",
        "test_features = np.reshape(trunc_model.predict(x_test),(850,-1))\n",
        "\n",
        "print(np.shape(train_features))\n",
        "print(np.shape(test_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(10,100,10):\n",
        "    clf = LinearDiscriminantAnalysis(n_components=i)\n",
        "    clf.fit(train_features, np.argmax(y_train,axis=-1))\n",
        "    pred = clf.predict(test_features)\n",
        "    print(i,\"acc : \", np.sum(pred==np.argmax(y_test,axis=-1))/len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results with LDA are not as good as a simple MobileNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Boosting Mobilenet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gb = sklearn.ensemble.GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0,verbose=1)\n",
        "gb.fit(train_features, np.argmax(y_train,axis=-1))\n",
        "pred = gb.predict(test_features)\n",
        "print(\"acc : \", np.sum(pred==np.argmax(y_test,axis=-1))/len(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GB is too slow to train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensembles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Weighted vote"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model 0\n",
            "0.7658824\n",
            "model 1\n",
            "0.7482353\n",
            "model 2\n",
            "0.74941176\n",
            "model 3\n",
            "0.7635294\n",
            "model 4\n",
            "0.74588233\n",
            "model 5\n",
            "0.7364706\n",
            "0.7752941\n"
          ]
        }
      ],
      "source": [
        "#best (soumis): \n",
        "\"\"\"\n",
        "models_init = [mobile5,mobile6,mobile7,mobile5,mobile6,mobile7,mobile5,mobile6,mobile7]\n",
        "weights = [\"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\", \"last_mob5_120.h5\",\"last_mob6_120.h5\",\"last_mob7_120.h5\",\n",
        "            \"mob5.56-0.7576.h5\",\"mob6.60-0.7294.h5\",\"mob7.59-0.7212.h5\"]\n",
        "\"\"\"\n",
        "#0.7717647\n",
        "\n",
        "#best 2 : \n",
        "\"\"\"\n",
        "models_init = [mobile5,mobile6,mobile7,mobile5,mobile6,mobile7]#,mobile5,mobile6,mobile7]\n",
        "weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "            \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "            ]\n",
        "\"\"\"\n",
        "#0.7752941\n",
        "\n",
        "pred = []\n",
        "models = []\n",
        "\n",
        "models_init = [mobile5,mobile6,mobile7,mobile5,mobile6,mobile7]#,mobile5,mobile6,mobile7]\n",
        "weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "            \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "            ]\n",
        "\n",
        "for i in range(len(models_init)):\n",
        "    models.append(models_init[i]())\n",
        "    models[i].load_weights(weights[i])\n",
        "    pred.append(models[i](x_test,training=False))\n",
        "    print(\"model\",i)\n",
        "    evaluate_pred(pred[i],y_test)\n",
        "\n",
        "moy = sum([mod.predict(x_test) for mod in models])/len(models)\n",
        "evaluate_pred(moy,y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_89\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_46 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_814 (Conv2D)          (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck_259 (Bottleneck)  (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_260 (Bottleneck)  (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_261 (Bottleneck)  (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_262 (Bottleneck)  (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_263 (Bottleneck)  (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_264 (Bottleneck)  (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_265 (Bottleneck)  (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_37 (MaxPooling (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_835 (Conv2D)          (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape_37 (Reshape)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Softmax_37 (Tens [(None, 100)]             0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 303,020\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n",
            "Model: \"functional_101\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_45 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_89 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_91 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_93 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_95 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_97 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_99 (Functional)      (None, 100)          309484      input_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 600)          0           functional_89[0][0]              \n",
            "                                                                 functional_91[0][0]              \n",
            "                                                                 functional_93[0][0]              \n",
            "                                                                 functional_95[0][0]              \n",
            "                                                                 functional_97[0][0]              \n",
            "                                                                 functional_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100)          60100       concatenate_5[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,917,004\n",
            "Trainable params: 60,100\n",
            "Non-trainable params: 1,856,904\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def dense_all():\n",
        "    models_init = [mobile5,mobile6,mobile7,\n",
        "                    mobile5,mobile6,mobile7]#,mobile5,mobile6,mobile7]\n",
        "    weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "                \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "                ]\n",
        "\n",
        "    nb = len(models_init)\n",
        "    #0.7752941\n",
        "\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    subs =[models_init[i]() for i in range(nb)]\n",
        "   \n",
        "    y =[]\n",
        "    for i in range(nb):\n",
        "        subs[i].load_weights(weights[i])\n",
        "        subs[i].trainable = False\n",
        "        y.append(subs[i](input_layer))\n",
        "    y = layers.Concatenate()(y)\n",
        "    y = layers.Dense(100,activation=\"softmax\")(y)\n",
        "    model = Model(inputs=input_layer,outputs=y)\n",
        "    return model\n",
        "model = dense_all()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_169\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_74 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1342 (Conv2D)         (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck_427 (Bottleneck)  (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_428 (Bottleneck)  (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_429 (Bottleneck)  (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_430 (Bottleneck)  (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_431 (Bottleneck)  (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_432 (Bottleneck)  (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_433 (Bottleneck)  (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1363 (Conv2D)         (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape_61 (Reshape)         (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 0\n",
            "Non-trainable params: 309,484\n",
            "_________________________________________________________________\n",
            "Model: \"functional_181\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_73 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_169 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_171 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_173 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_175 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_177 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_179 (Functional)     (None, 100)          309484      input_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 600)          0           functional_169[0][0]             \n",
            "                                                                 functional_171[0][0]             \n",
            "                                                                 functional_173[0][0]             \n",
            "                                                                 functional_175[0][0]             \n",
            "                                                                 functional_177[0][0]             \n",
            "                                                                 functional_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          60100       concatenate_9[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,917,004\n",
            "Trainable params: 60,100\n",
            "Non-trainable params: 1,856,904\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def dense_all_wo_softmax():\n",
        "    models_init = [mobile5,mobile6,mobile7,\n",
        "                    mobile5,mobile6,mobile7]#,mobile5,mobile6,mobile7]\n",
        "    weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "                \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "                ]\n",
        "\n",
        "    nb = len(models_init)\n",
        "    #0.7752941\n",
        "\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    subs =[models_init[i]() for i in range(nb)]\n",
        "   \n",
        "    y =[]\n",
        "    for i in range(nb):\n",
        "        subs[i].load_weights(weights[i])\n",
        "        subs[i].trainable = False\n",
        "        subs[i] = Model(subs[i].inputs,subs[i].layers[-2].output)\n",
        "        y.append(subs[i](input_layer))\n",
        "    #subs[0].summary()\n",
        "    y = layers.Concatenate()(y)\n",
        "    y = layers.Dense(100,activation=\"softmax\")(y)\n",
        "    model = Model(inputs=input_layer,outputs=y)\n",
        "    return model\n",
        "model = dense_all_wo_softmax()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"functional_195\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_81 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1474 (Conv2D)         (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "bottleneck_469 (Bottleneck)  (None, 28, 28, 16)        2688      \n",
            "_________________________________________________________________\n",
            "bottleneck_470 (Bottleneck)  (None, 14, 14, 24)        5688      \n",
            "_________________________________________________________________\n",
            "bottleneck_471 (Bottleneck)  (None, 7, 7, 32)          10832     \n",
            "_________________________________________________________________\n",
            "bottleneck_472 (Bottleneck)  (None, 4, 4, 32)          15968     \n",
            "_________________________________________________________________\n",
            "bottleneck_473 (Bottleneck)  (None, 4, 4, 64)          24256     \n",
            "_________________________________________________________________\n",
            "bottleneck_474 (Bottleneck)  (None, 4, 4, 96)          75072     \n",
            "_________________________________________________________________\n",
            "bottleneck_475 (Bottleneck)  (None, 2, 2, 160)         158560    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_67 (MaxPooling (None, 1, 1, 160)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1495 (Conv2D)         (None, 1, 1, 100)         16100     \n",
            "_________________________________________________________________\n",
            "reshape_67 (Reshape)         (None, 100)               0         \n",
            "=================================================================\n",
            "Total params: 309,484\n",
            "Trainable params: 0\n",
            "Non-trainable params: 309,484\n",
            "_________________________________________________________________\n",
            "Model: \"functional_207\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_80 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "functional_195 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_197 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_199 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_201 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_203 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "functional_205 (Functional)     (None, 100)          309484      input_80[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 600)          0           functional_195[0][0]             \n",
            "                                                                 functional_197[0][0]             \n",
            "                                                                 functional_199[0][0]             \n",
            "                                                                 functional_201[0][0]             \n",
            "                                                                 functional_203[0][0]             \n",
            "                                                                 functional_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_686 (Dropout)           (None, 600)          0           concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 100)          60100       dropout_686[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 1,917,004\n",
            "Trainable params: 60,100\n",
            "Non-trainable params: 1,856,904\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def dense_all_wo_softmax_dropout():\n",
        "    models_init = [mobile5,mobile6,mobile7,\n",
        "                    mobile5,mobile6,mobile7]#,mobile5,mobile6,mobile7]\n",
        "    weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "                \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "                ]\n",
        "\n",
        "    nb = len(models_init)\n",
        "    #0.7752941\n",
        "\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    subs =[models_init[i]() for i in range(nb)]\n",
        "   \n",
        "    y =[]\n",
        "    for i in range(nb):\n",
        "        subs[i].load_weights(weights[i])\n",
        "        subs[i].trainable = False\n",
        "        subs[i] = Model(subs[i].inputs,subs[i].layers[-2].output)\n",
        "        y.append(subs[i](input_layer))\n",
        "    #subs[0].summary()\n",
        "    y = layers.Concatenate()(y)\n",
        "    y = layers.Dropout(0.2)(y)\n",
        "    y = layers.Dense(100,activation=\"softmax\")(y)\n",
        "    model = Model(inputs=input_layer,outputs=y)\n",
        "    return model\n",
        "model = dense_all_wo_softmax_dropout()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_all_wo_softmax_dropout():\n",
        "    models_init = [mobile5,mobile6,mobile7,\n",
        "                    mobile5,mobile6,mobile7]\n",
        "    weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "                \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"mob7.110-0.7365-0.6424.h5\"\n",
        "                ]\n",
        "\n",
        "    nb = len(models_init)\n",
        "    #0.7752941\n",
        "\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    subs =[models_init[i]() for i in range(nb)]\n",
        "   \n",
        "    y =[]\n",
        "    for i in range(nb):\n",
        "        subs[i].load_weights(weights[i])\n",
        "        subs[i].trainable = False\n",
        "        subs[i] = Model(subs[i].inputs,subs[i].layers[-2].output)\n",
        "        y.append(subs[i](input_layer))\n",
        "    #subs[0].summary()\n",
        "    y = layers.Concatenate()(y)\n",
        "    y = layers.Dropout(0.2)(y)\n",
        "    y = layers.Dense(100,activation=\"softmax\")(y)\n",
        "    model = Model(inputs=input_layer,outputs=y)\n",
        "    return model\n",
        "model = dense_all_wo_softmax_dropout()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dense_all_wo_softmax_dropout2():\n",
        "    models_init = [mobile5,mobile6,mobile7,\n",
        "                    mobile5,mobile6,mobile5]\n",
        "    weights = [\"mob5.159-0.7659-0.7465.h5\",\"mob6.158-0.7482-0.6675.h5\",\"mob7.168-0.7494-0.6603.h5\",\n",
        "                \"mob5.118-0.7635-0.7393.h5\",\"mob6.106-0.7459-0.6574.h5\",\"n2_mob5.100-0.7682-0.7933.h5\"\n",
        "                ]\n",
        "\n",
        "    nb = len(models_init)\n",
        "    #0.7752941\n",
        "\n",
        "    input_layer = layers.Input(shape=(28,28,1))\n",
        "    subs =[models_init[i]() for i in range(nb)]\n",
        "   \n",
        "    y =[]\n",
        "    for i in range(nb):\n",
        "        subs[i].load_weights(weights[i])\n",
        "        subs[i].trainable = False\n",
        "        subs[i] = Model(subs[i].inputs,subs[i].layers[-2].output)\n",
        "        y.append(subs[i](input_layer))\n",
        "    #subs[0].summary()\n",
        "    y = layers.Concatenate()(y)\n",
        "    y = layers.Dropout(0.2)(y)\n",
        "    y = layers.Dense(100,activation=\"softmax\")(y)\n",
        "    model = Model(inputs=input_layer,outputs=y)\n",
        "    return model\n",
        "model = dense_all_wo_softmax_dropout()\n",
        "model.summary()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 4.1635 - accuracy: 0.3724 - val_loss: 2.8369 - val_accuracy: 0.6988\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 3.0445 - accuracy: 0.5950 - val_loss: 2.7102 - val_accuracy: 0.7353\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 37s 369ms/step - loss: 2.8685 - accuracy: 0.6431 - val_loss: 2.6455 - val_accuracy: 0.7553\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 36s 365ms/step - loss: 2.7616 - accuracy: 0.6730 - val_loss: 2.6353 - val_accuracy: 0.7565\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 2.6895 - accuracy: 0.6868 - val_loss: 2.6067 - val_accuracy: 0.7576\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 37s 366ms/step - loss: 2.6511 - accuracy: 0.6938 - val_loss: 2.5809 - val_accuracy: 0.7706\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.5978 - accuracy: 0.7057 - val_loss: 2.5670 - val_accuracy: 0.7671\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 2.5725 - accuracy: 0.7117 - val_loss: 2.5353 - val_accuracy: 0.7800\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.5551 - accuracy: 0.7195 - val_loss: 2.5255 - val_accuracy: 0.7800\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.5247 - accuracy: 0.7253 - val_loss: 2.5311 - val_accuracy: 0.7612\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 2.5191 - accuracy: 0.7259 - val_loss: 2.5186 - val_accuracy: 0.7812\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.4894 - accuracy: 0.7359 - val_loss: 2.5043 - val_accuracy: 0.7753\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 36s 364ms/step - loss: 2.4891 - accuracy: 0.7359 - val_loss: 2.4942 - val_accuracy: 0.7824\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.4856 - accuracy: 0.7345 - val_loss: 2.5200 - val_accuracy: 0.7694\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4897 - accuracy: 0.7325 - val_loss: 2.4956 - val_accuracy: 0.7729\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4783 - accuracy: 0.7363 - val_loss: 2.5210 - val_accuracy: 0.7647\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4775 - accuracy: 0.7389 - val_loss: 2.4769 - val_accuracy: 0.7718\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4624 - accuracy: 0.7404 - val_loss: 2.4980 - val_accuracy: 0.7788\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4542 - accuracy: 0.7425 - val_loss: 2.4775 - val_accuracy: 0.7753\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4529 - accuracy: 0.7438 - val_loss: 2.4880 - val_accuracy: 0.7682\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4614 - accuracy: 0.7402 - val_loss: 2.4908 - val_accuracy: 0.7612\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4613 - accuracy: 0.7364 - val_loss: 2.5084 - val_accuracy: 0.7671\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4507 - accuracy: 0.7456 - val_loss: 2.4954 - val_accuracy: 0.7800\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4559 - accuracy: 0.7423 - val_loss: 2.5024 - val_accuracy: 0.7706\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4495 - accuracy: 0.7435 - val_loss: 2.4873 - val_accuracy: 0.7718\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4512 - accuracy: 0.7468 - val_loss: 2.4798 - val_accuracy: 0.7812\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 37s 365ms/step - loss: 2.4531 - accuracy: 0.7396 - val_loss: 2.4770 - val_accuracy: 0.7906\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4537 - accuracy: 0.7428 - val_loss: 2.4841 - val_accuracy: 0.7682\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4505 - accuracy: 0.7439 - val_loss: 2.4794 - val_accuracy: 0.7741\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4241 - accuracy: 0.7498 - val_loss: 2.4765 - val_accuracy: 0.7706\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4320 - accuracy: 0.7505 - val_loss: 2.4622 - val_accuracy: 0.7824\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4245 - accuracy: 0.7532 - val_loss: 2.4681 - val_accuracy: 0.7800\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4222 - accuracy: 0.7515 - val_loss: 2.4684 - val_accuracy: 0.7647\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4287 - accuracy: 0.7521 - val_loss: 2.4639 - val_accuracy: 0.7824\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4282 - accuracy: 0.7504 - val_loss: 2.4701 - val_accuracy: 0.7718\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4076 - accuracy: 0.7569 - val_loss: 2.4725 - val_accuracy: 0.7741\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4093 - accuracy: 0.7552 - val_loss: 2.4641 - val_accuracy: 0.7718\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4240 - accuracy: 0.7483 - val_loss: 2.4687 - val_accuracy: 0.7741\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4204 - accuracy: 0.7559 - val_loss: 2.4698 - val_accuracy: 0.7718\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4272 - accuracy: 0.7528 - val_loss: 2.4586 - val_accuracy: 0.7741\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4157 - accuracy: 0.7545 - val_loss: 2.4638 - val_accuracy: 0.7718\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3877 - accuracy: 0.7616 - val_loss: 2.4668 - val_accuracy: 0.7718\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3996 - accuracy: 0.7577 - val_loss: 2.4436 - val_accuracy: 0.7753\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4072 - accuracy: 0.7568 - val_loss: 2.4526 - val_accuracy: 0.7824\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.4081 - accuracy: 0.7546 - val_loss: 2.4511 - val_accuracy: 0.7753\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.4086 - accuracy: 0.7559 - val_loss: 2.4422 - val_accuracy: 0.7776\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3960 - accuracy: 0.7607 - val_loss: 2.4282 - val_accuracy: 0.7906\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3938 - accuracy: 0.7595 - val_loss: 2.4386 - val_accuracy: 0.7847\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.3743 - accuracy: 0.7666 - val_loss: 2.4342 - val_accuracy: 0.7835\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3963 - accuracy: 0.7609 - val_loss: 2.4218 - val_accuracy: 0.7871\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3730 - accuracy: 0.7629 - val_loss: 2.4223 - val_accuracy: 0.7788\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3905 - accuracy: 0.7607 - val_loss: 2.4345 - val_accuracy: 0.7776\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 36s 359ms/step - loss: 2.3821 - accuracy: 0.7618 - val_loss: 2.4257 - val_accuracy: 0.7753\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 36s 360ms/step - loss: 2.3787 - accuracy: 0.7660 - val_loss: 2.4392 - val_accuracy: 0.7847\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 36s 361ms/step - loss: 2.3781 - accuracy: 0.7646 - val_loss: 2.4313 - val_accuracy: 0.7835\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3735 - accuracy: 0.7648 - val_loss: 2.4254 - val_accuracy: 0.7765\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3802 - accuracy: 0.7620 - val_loss: 2.4229 - val_accuracy: 0.7788\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3771 - accuracy: 0.7650 - val_loss: 2.4285 - val_accuracy: 0.7812\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3726 - accuracy: 0.7663 - val_loss: 2.4325 - val_accuracy: 0.7753\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3703 - accuracy: 0.7658 - val_loss: 2.4284 - val_accuracy: 0.7753\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3712 - accuracy: 0.7663 - val_loss: 2.4273 - val_accuracy: 0.7788\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3764 - accuracy: 0.7623 - val_loss: 2.4274 - val_accuracy: 0.7824\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3684 - accuracy: 0.7680 - val_loss: 2.4270 - val_accuracy: 0.7788\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3780 - accuracy: 0.7635 - val_loss: 2.4251 - val_accuracy: 0.7812\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3680 - accuracy: 0.7686 - val_loss: 2.4233 - val_accuracy: 0.7824\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3664 - accuracy: 0.7666 - val_loss: 2.4235 - val_accuracy: 0.7776\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3720 - accuracy: 0.7677 - val_loss: 2.4262 - val_accuracy: 0.7788\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3625 - accuracy: 0.7696 - val_loss: 2.4195 - val_accuracy: 0.7765\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3728 - accuracy: 0.7673 - val_loss: 2.4226 - val_accuracy: 0.7765\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3902 - accuracy: 0.7593 - val_loss: 2.4220 - val_accuracy: 0.7776\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3650 - accuracy: 0.7693 - val_loss: 2.4229 - val_accuracy: 0.7753\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3692 - accuracy: 0.7670 - val_loss: 2.4225 - val_accuracy: 0.7788\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3678 - accuracy: 0.7679 - val_loss: 2.4244 - val_accuracy: 0.7765\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3741 - accuracy: 0.7639 - val_loss: 2.4202 - val_accuracy: 0.7800\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3619 - accuracy: 0.7659 - val_loss: 2.4231 - val_accuracy: 0.7812\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3701 - accuracy: 0.7661 - val_loss: 2.4210 - val_accuracy: 0.7812\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3724 - accuracy: 0.7667 - val_loss: 2.4222 - val_accuracy: 0.7741\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3589 - accuracy: 0.7698 - val_loss: 2.4180 - val_accuracy: 0.7812\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3683 - accuracy: 0.7682 - val_loss: 2.4194 - val_accuracy: 0.7824\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3651 - accuracy: 0.7679 - val_loss: 2.4180 - val_accuracy: 0.7753\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3647 - accuracy: 0.7698 - val_loss: 2.4189 - val_accuracy: 0.7835\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3686 - accuracy: 0.7675 - val_loss: 2.4200 - val_accuracy: 0.7800\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3621 - accuracy: 0.7675 - val_loss: 2.4204 - val_accuracy: 0.7788\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3658 - accuracy: 0.7718 - val_loss: 2.4214 - val_accuracy: 0.7788\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3585 - accuracy: 0.7704 - val_loss: 2.4190 - val_accuracy: 0.7812\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3620 - accuracy: 0.7671 - val_loss: 2.4171 - val_accuracy: 0.7824\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 36s 356ms/step - loss: 2.3686 - accuracy: 0.7698 - val_loss: 2.4192 - val_accuracy: 0.7776\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3624 - accuracy: 0.7699 - val_loss: 2.4192 - val_accuracy: 0.7765\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3613 - accuracy: 0.7721 - val_loss: 2.4181 - val_accuracy: 0.7788\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.3611 - accuracy: 0.7714 - val_loss: 2.4189 - val_accuracy: 0.7824\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 36s 358ms/step - loss: 2.3608 - accuracy: 0.7682 - val_loss: 2.4175 - val_accuracy: 0.7835\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 36s 357ms/step - loss: 2.3544 - accuracy: 0.7723 - val_loss: 2.4187 - val_accuracy: 0.7812\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 36s 355ms/step - loss: 2.3771 - accuracy: 0.7663 - val_loss: 2.4200 - val_accuracy: 0.7765\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 35s 353ms/step - loss: 2.3588 - accuracy: 0.7698 - val_loss: 2.4189 - val_accuracy: 0.7788\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 35s 353ms/step - loss: 2.3616 - accuracy: 0.7694 - val_loss: 2.4198 - val_accuracy: 0.7776\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 35s 352ms/step - loss: 2.3511 - accuracy: 0.7734 - val_loss: 2.4193 - val_accuracy: 0.7788\n",
            "Epoch 97/100\n",
            " 16/100 [===>..........................] - ETA: 27s - loss: 2.3610 - accuracy: 0.7654"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-77-83b6487a8b6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     save_best_only=True)\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrlr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\n",
        "#model.load_weights()\n",
        "model.compile(optimizer=opt, \n",
        "            loss=loss, \n",
        "            metrics=['accuracy'])\n",
        "rlr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss', factor=0.7, patience=3, verbose=0,\n",
        "    mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "\n",
        "\n",
        "checkpoint_filepath = 'best_of_all_wo_softmax_dropout2.{epoch:02d}-{val_accuracy:.4f}-{accuracy:.4f}.h5'\n",
        "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 256 ,epochs=100,validation_data=(x_test,y_test),callbacks = [model_checkpoint_callback,rlr],initial_epoch=0,steps_per_epoch=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = dense_all_wo_softmax_dropout()\n",
        "model.load_weights(\"best_of_all_wo_softmax_dropout.27-0.7906-0.7396.h5\")\n",
        "evaluate_pred(model.predict(x_test),y_test)\n",
        "\n",
        "prediction = model.predict(x_compet)\n",
        "np.save(\"prediction.npy\", prediction)\n",
        "print(np.shape(x_compet))\n",
        "print(np.shape(prediction))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save_weights(\"best_of_all.61-0.7788-0.7826.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nQOHhrihGLRw"
      ],
      "name": "compet_gda.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
